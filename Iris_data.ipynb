{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = pd.read_csv('iris_data.csv')\n",
    "iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.species.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.loc[iris['species']=='virginica','species']=0\n",
    "iris.loc[iris['species']=='versicolor','species']=1\n",
    "iris.loc[iris['species']=='setosa','species'] = 2\n",
    "iris = iris[iris['species']!=2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris[['petal_length', 'petal_width']].values.T\n",
    "Y = iris[['species']].values.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[0, :], X[1, :], c=Y[0,:], s=40, cmap=plt.cm.Spectral);\n",
    "plt.title(\"IRIS DATA | Blue - Versicolor, Red - Virginica \")\n",
    "plt.xlabel('Petal Length')\n",
    "plt.ylabel('Petal Width')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(n_x, n_h, n_y):   \n",
    "    np.random.seed(41)\n",
    "    W1 = np.random.randn(n_h, n_x) * 0.01\n",
    "    b1 = np.zeros(shape=(n_h, 1))\n",
    "    W2 = np.random.randn(n_y, n_h)\n",
    "    b2 = np.zeros(shape=(n_y, 1))\n",
    "    \n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_sizes(X, Y):\n",
    "    n_x = X.shape[0] \n",
    "    n_y = Y.shape[0] \n",
    "    return (n_x, n_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Forward \n",
    "Now that you have initialized your parameters, you will do the forward propagation module. You will start by implementing some basic functions that you will use later when implementing the model. You will complete three functions in this order:\n",
    "\n",
    "- LINEAR\n",
    "- LINEAR -> ACTIVATION where ACTIVATION will be either tanH or Sigmoid. \n",
    "- [LINEAR -> tanH] $\\times$ (L-1) -> LINEAR -> SIGMOID (whole model)\n",
    "\n",
    "The linear forward module (vectorized over all the examples) computes the following equations:\n",
    "\n",
    "$$Z^{[l]} = W^{[l]}A^{[l-1]} +b^{[l]}\\tag{4}$$\n",
    "\n",
    "where $A^{[0]} = X$. \n",
    "\n",
    "### Linear-Activation Forward\n",
    "\n",
    "In this notebook, you will use two activation functions:\n",
    "\n",
    "- **tanH**: $A = tanH(Z) = tanH(W A + b)$.\n",
    "``` python\n",
    "```\n",
    "\n",
    "- **Sigmoid**: $A = \\sigma(Z) = \\sigma(W A + b) = \\frac{1}{ 1 + e^{-(W A + b)}}$.\n",
    "``` python\n",
    "```\n",
    "\n",
    "For more convenience, you are going to group two functions (Linear and Activation) into one function (LINEAR->ACTIVATION). Hence, you will implement a function that does the LINEAR forward step followed by an ACTIVATION forward step.\n",
    "\n",
    "**Exercise**: Build the *LINEAR* part of forward propagation.\n",
    "    \n",
    "**Exercise**: Implement the forward propagation of the *LINEAR->ACTIVATION* layer. Mathematical relation is: $A^{[l]} = g(Z^{[l]}) = g(W^{[l]}A^{[l-1]} +b^{[l]})$ where the activation \"g\" can be sigmoid() or tanh().\n",
    "\n",
    "**Reminder**:\n",
    "The mathematical representation of the *LINEAR* unit is $Z^{[l]} = W^{[l]}A^{[l-1]} +b^{[l]}$. You may also find `np.dot()` useful. If your dimensions don't match, printing `W.shape` may help. While implementing the activation functions,`np.tanh()` and `np.exp()` may be useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters):\n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    \n",
    "    #Enter your code here\n",
    "    Z1 = \n",
    "    A1 =    ##TanH activation function\n",
    "    Z2 = \n",
    "    A2 =     ##Sigmoid function\n",
    "    \n",
    "    return A2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you need to compute the cost, because you want to check if your model is actually learning.\n",
    "\n",
    "**Exercise**: Compute the cross-entropy cost, using the following formula: $$-\\frac{1}{m} \\sum\\limits_{i = 1}^{m} (y\\log\\left(A^{[l]}\\right) + (1-y)\\log\\left(1- A^{[l]}\\right))Â \\tag{7}$$\n",
    "\n",
    "**Reminder**:\n",
    "While implementing the cost function,`np.log()`, `np.multiply()` and `np.sum()` may be useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(A2, Y, parameters):\n",
    "   \n",
    "    m = Y.shape[1] # number of training examples\n",
    "    \n",
    "    W1 = parameters['W1']\n",
    "    W2 = parameters['W2']\n",
    "    \n",
    "    # Compute cross-entropy cost\n",
    "    cost = \n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### NN model ###\n",
    "def nn_model(X, Y, n_h, num_iterations=10):\n",
    "    np.random.seed(41)\n",
    "    n_x = layer_sizes(X, Y)[0]\n",
    "    n_y = layer_sizes(X, Y)[1]\n",
    "    \n",
    "    parameters = initialize_parameters(n_x, n_h, n_y)\n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    \n",
    "    # Loop (gradient descent)\n",
    "    for i in range(0, num_iterations):\n",
    "         \n",
    "        # Forward propagation. Inputs: \"X, parameters\". Outputs: \"A\".\n",
    "        A2 = forward_propagation(X, parameters)\n",
    "        \n",
    "        # Cost function. Inputs: \"A2, Y, parameters\". Outputs: \"cost\".\n",
    "        cost = compute_cost(A2, Y, parameters)\n",
    " \n",
    "        print (\"Cost after iteration %i: %f\" % (i, cost))\n",
    "    return parameters,n_h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = nn_model(X,Y , n_h = 1, num_iterations=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
